{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jSDVZTzsIi92"
   },
   "source": [
    "# Этап 1. Парсинг данных\n",
    "\n",
    "В этом разделе собираем данные для дальнейшего анализа.\n",
    "\n",
    "[Источник](https://www.imdb.com/search/title/?title_type=feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aHuKBd2au3MB",
    "outputId": "7803f07f-4c3b-4df7-e001-87df305b4cec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.11/site-packages (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.11/site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.11/site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.11/site-packages (from requests) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.11/site-packages (from requests) (2024.2.2)\n",
      "zsh:1: unmatched `\n"
     ]
    }
   ],
   "source": [
    "!pip install requests\n",
    "!pip install beautifulsoup4`\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W318k1mQI1QW"
   },
   "source": [
    "Создадим функцию, которая будет собирать необходиимые данные с 1 страницы (на странице 50 фильмов)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Fj4RxHwcIhmv"
   },
   "outputs": [],
   "source": [
    "def parse_imdb_page():\n",
    "    while True:\n",
    "        url = yield\n",
    "        response = requests.get(url=url, headers={'Accept-Language': 'ru-RU,ru;q=0.9,en-US;q=0.8,en;q=0.7'})\n",
    "        if not response.ok:\n",
    "            return None\n",
    "\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        all_films = soup.find_all('div', class_='lister-item mode-advanced')\n",
    "        # 'div' - тег блока, под которым у нас вся инфа о фильме. class_ - класс блока\n",
    "\n",
    "        parsed_films_list = []\n",
    "\n",
    "        for film in all_films:\n",
    "            if (film_content := film.find('div', class_='lister-item-content')) is not None:\n",
    "                film_header = film_content.find('h3', class_='lister-item-header')\n",
    "                film_name = film_header.find('a').text.strip()\n",
    "                film_url = film_header.find('a')['href']\n",
    "                film_global_rate = film_header.find('span', class_='lister-item-index unbold text-primary').text.strip()\n",
    "                film_year = film_header.find('span', class_='lister-item-year text-muted unbold').text.strip()\n",
    "                film_rates = film_content.find('div', class_='ratings-bar')\n",
    "\n",
    "                try: # Не у всех фильмов есть отметки на meta score & imdb. Поэтому пробуем их найти\n",
    "                    film_imdb_rate = film_rates.find('div', class_='inline-block ratings-imdb-rating')['data-value'] # rate по imdb\n",
    "                    film_meta_score_rate = film_rates.find('div', class_='inline-block ratings-metascore').find('span').text.strip() # rate на meta score\n",
    "                except:\n",
    "                    film_imdb_rate = None\n",
    "                    film_meta_score_rate = None\n",
    "\n",
    "                film_muted_spans = film_content.find_all('p', class_='text-muted')\n",
    "\n",
    "                for film_desc in film_muted_spans:\n",
    "                    genre = film_desc.find('span', class_='genre')\n",
    "                    duration = film_desc.find('span', class_='runtime')\n",
    "                    if genre or duration:\n",
    "                        film_duration = None if not duration else duration.text.strip()\n",
    "                        if genre is not None:\n",
    "                            film_genre = genre.text.strip()\n",
    "                        else:\n",
    "                            film_genre = None\n",
    "                    else:\n",
    "                        film_description = film_desc.text.strip()\n",
    "\n",
    "                try: # Не у всех фильмов есть кол-во голосов, так что пробуем их найти\n",
    "                    film_votes = film_content.find('p', class_='sort-num_votes-visible').find(\n",
    "                        'span',\n",
    "                        attrs={'name': 'nv'}\n",
    "                    )['data-value']\n",
    "                except:\n",
    "                    film_votes = None\n",
    "\n",
    "                parsed_films_list.append({\n",
    "                    'name': film_name,\n",
    "                    'url': film_url,\n",
    "                    'global_rate': film_global_rate,\n",
    "                    'release_year': film_year,\n",
    "                    'imdb_rate': film_imdb_rate,\n",
    "                    'metascore_rate': film_meta_score_rate,\n",
    "                    'description': film_description,\n",
    "                    'votes': film_votes,\n",
    "                    'duration': film_duration,\n",
    "                    'genre': film_genre\n",
    "                })\n",
    "\n",
    "        yield parsed_films_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fxg27DvsI-oJ"
   },
   "source": [
    "Соберем функцию, чтобы мы могли спокойно переключаться между страницами и собрать большую базу."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_imdb_page():\n",
    "    response = requests.get(\"https://www.imdb.com/search/title/?title_type=feature\", headers=headers)\n",
    "    print(\"✅ Ответ IMDb:\", response.status_code)\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        print(\"❌ IMDb заблокировал запрос!\")\n",
    "        return\n",
    "\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    movies = soup.find_all('div', class_='lister-item mode-advanced')\n",
    "    \n",
    "    if not movies:\n",
    "        print(\"❌ Фильмы не найдены! IMDb мог изменить HTML.\")\n",
    "        return\n",
    "    \n",
    "    for movie in movies:\n",
    "        yield movie.h3.a.text  # Пример работы генератора\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "iX7kqdhWJqtB"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'return' outside function (905331548.py, line 10)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[14], line 10\u001b[0;36m\u001b[0m\n\u001b[0;31m    return []\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m 'return' outside function\n"
     ]
    }
   ],
   "source": [
    "def get_result(max_count: int = 5000):\n",
    "    cour = parse_imdb_page()\n",
    "\n",
    "\n",
    "try:\n",
    "    value = next(cour)  # Проверяем генератор\n",
    "    print(\"✅ Генератор запущен:\", value)\n",
    "except StopIteration:\n",
    "    print(\"❌ Ошибка: `parse_imdb_page()` завершился сразу!\")\n",
    "    return []\n",
    "\n",
    "    info = cour.send('https://www.imdb.com/search/title/?title_type=feature')\n",
    "    \n",
    "    for count in range(51, max_count, 50):\n",
    "        next_url = f'https://www.imdb.com/search/title/?title_type=feature&start={count}&ref_=adv_nxt'\n",
    "        try:\n",
    "            next(cour)\n",
    "            info += cour.send(next_url)\n",
    "        except StopIteration:\n",
    "            print(f\"❌ Ошибка: Генератор завершился на странице {count}\")\n",
    "            break  # Останавливаем цикл\n",
    "\n",
    "    cour.close()\n",
    "    return info  # Теперь return внутри функции!\n",
    "\n",
    "# Запускаем функцию\n",
    "result = get_result()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U4jZ-x-yJzLX"
   },
   "source": [
    "Соберем наши данные в файл:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vt3ZuWKKJsTw"
   },
   "outputs": [],
   "source": [
    "\n",
    "df = pd.DataFrame(result, columns=list(result[0].keys()))\n",
    "df.to_csv('list.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4va_OSIrRNEw"
   },
   "source": [
    "Данные лежат в файле list.csv, уберем в табличке ссылки на фильмы и будет готово!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 337
    },
    "id": "7aOQ-ASQRS4h",
    "outputId": "6614dd15-d1ee-4928-c4b2-688e4d60093a"
   },
   "outputs": [],
   "source": [
    "df = df.drop('url', axis=1)\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
